{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJlJO1RSGaMvsU6mCFRg9V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LukeSchreiber/FastAI-Projects/blob/main/Lesson6RandomForests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is my random forest project. This project uses a Random Forest classifier to predict whether Bitcoins price will go up or down the next day based on historical market features."
      ],
      "metadata": {
        "id": "h4TrtaDc1BaJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First off we need to import everything. Were importing pandas to get together the data smoothly then numpy to crunch all the numbers, yfianance in order to get the data we need. while were going to use sklearn to make the random forest. Matplotlib to plot and graph what we need"
      ],
      "metadata": {
        "id": "7eclLqTm1bYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = yf.download(\"BTC-USD\", interval=\"1d\", auto_adjust=False)\n",
        "df = df.dropna().copy()\n",
        "\n",
        "df = df[['Open','High','Low','Close','Volume']].copy()\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "puaaU7GBeGxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to set the feature matrix (x) and target (y)"
      ],
      "metadata": {
        "id": "Q86KusrV59r3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(index=df.index)\n",
        "\n",
        "X['pct_oc'] = (df['Close'] - df['Open']) / df['Open']\n",
        "\n",
        "X['range_hl'] = (df['High'] - df['Low']) / df['Open']\n",
        "\n",
        "#Volume z-score (14d)\n",
        "vol = df['Volume']\n",
        "X['vol_z14'] = (vol - vol.rolling(14).mean()) / vol.rolling(14).std()\n",
        "\n",
        "X = X.dropna()\n",
        "\n",
        "y = (df['Close'].shift(-1) > df['Close']).astype(int).reindex(X.index)\n",
        "\n",
        "X.head(), y.head()\n"
      ],
      "metadata": {
        "id": "JwccorM7iSXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "split 80/20"
      ],
      "metadata": {
        "id": "X7IciBcK6GM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_idx = int(len(X) * 0.8)\n",
        "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
        "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
        "\n",
        "len(X_train), len(X_test)\n"
      ],
      "metadata": {
        "id": "VMCIcc40iUF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have clean and split data so lets create the model and train it."
      ],
      "metadata": {
        "id": "awjWId4Z6NXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Random forest training\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=None,\n",
        "    min_samples_leaf=3,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "bRPyTDoRiWgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the model is trained we can now use it to predict and evaluate"
      ],
      "metadata": {
        "id": "A-wOCchA876i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = rf.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, pred)\n",
        "cm = confusion_matrix(y_test, pred)\n",
        "print(f\"Accuracy: {acc:.3f}\\n\")\n",
        "print(\"Confusion matrix:\\n\", cm, \"\\n\")\n",
        "print(classification_report(y_test, pred, digits=3))\n"
      ],
      "metadata": {
        "id": "_aSr4KT5iYG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block will help us show the feature importance. How much each feature played into creating our model"
      ],
      "metadata": {
        "id": "DRVIcuPt97Wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imp = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "print(imp)\n",
        "\n",
        "imp.plot(kind='bar', title='Feature importances');\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VDcHCT8PiZeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can show the comparison of what happend vs what we predicted"
      ],
      "metadata": {
        "id": "fC1XTQJ_-Y2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "viz = pd.DataFrame({\n",
        "    'y_true': y_test.values.ravel(),   # flatten to 1D\n",
        "    'y_pred': pred.ravel()             # flatten to 1D\n",
        "}, index=y_test.index)\n",
        "\n",
        "viz.tail(30)\n"
      ],
      "metadata": {
        "id": "JeWrYcUSibER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the accuracy score and the classifaction report"
      ],
      "metadata": {
        "id": "ptceNqdw-9I6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
        "print(classification_report(y_test, pred))\n"
      ],
      "metadata": {
        "id": "dSO6y_UO01ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we can save it into model.pkl!"
      ],
      "metadata": {
        "id": "45HrGx8M_Auk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(rf, \"bitcoin_rf_model.pkl\")\n"
      ],
      "metadata": {
        "id": "xmN9PzyD-z4T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}