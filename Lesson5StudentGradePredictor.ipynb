{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPonDeeTTlRLZAZ308VGDOD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LukeSchreiber/FastAI-Projects/blob/main/Lesson5StudentGradePredictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hello, this is my fastai lesson 5 project. I built a student grade classifier. Its a simple pytorch model I built from scratch that predicts if a student will pass or fail based on: hours studied, attendace, previous grade."
      ],
      "metadata": {
        "id": "Rm67AgGZjgkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First were going to import everything we need and set the seed and check for GPU"
      ],
      "metadata": {
        "id": "u-zhr_HICkfz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BqeICxUO6W1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd14408d-6c35-45a0-8c66-a60838c6ab2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "#set the seed\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "#gpu check\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is where were going to create a fake dataset, you can delete this block and change around the next block in order to use a csv uploader but for the sake of this project IM going to create a dataset like this."
      ],
      "metadata": {
        "id": "9EHSuSIBD_pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate 100,000 student records\n",
        "n_students = 100000\n",
        "hours = np.random.uniform(0, 10, n_students)  # Hours studied (0-10)\n",
        "attendance = np.random.uniform(0, 100, n_students)  # Attendance (0-100%)\n",
        "prev_grade = np.random.uniform(0, 100, n_students)  # Previous grade (0-100)\n",
        "\n",
        "# Determine pass/fail\n",
        "pass_prob = np.clip(prev_grade / 100 + np.random.normal(0, 0.1, n_students), 0, 1)\n",
        "pass_status = (pass_prob > 0.6).astype(int)  # Pass if prob > 0.6\n",
        "\n",
        "# Data frame\n",
        "df = pd.DataFrame({\n",
        "    'hours': hours,\n",
        "    'attendance': prev_grade,\n",
        "    'prev_grade': prev_grade,\n",
        "    'pass': pass_status\n",
        "})\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv('student_grades_100k.csv', index=False)\n",
        "print(\"Generated and saved student_grades_100k.csv with 100,000 students!\")\n",
        "\n",
        "# Quick check\n",
        "print(\"\\nFirst 5 rows:\\n\", df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj2KE7H5NXSR",
        "outputId": "fb6d67a7-19f7-4447-8a94-46469f8decf8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated and saved student_grades_100k.csv with 100,000 students!\n",
            "\n",
            "First 5 rows:\n",
            "       hours  attendance  prev_grade  pass\n",
            "0  3.745401   28.258797   28.258797     0\n",
            "1  9.507143   45.867659   45.867659     0\n",
            "2  7.319939    9.921550    9.921550     0\n",
            "3  5.986585   44.683703   44.683703     0\n",
            "4  1.560186   20.308135   20.308135     0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now were going to take that csv we just created and upload it in"
      ],
      "metadata": {
        "id": "MF5rNPhIEMpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# CSV uploader (load the generated file)\n",
        "df = pd.read_csv('student_grades_100k.csv')  # Load the file we just created\n",
        "print(\"CSV loaded; file name: student_grades_100k.csv\")\n",
        "\n",
        "# Print the columns to see if the CSV is correct\n",
        "print(\"Available columns:\", df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZx0bQ_qAU8x",
        "outputId": "242f745e-2e45-4fba-d8c6-76d850f7f629"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV loaded; file name: student_grades_100k.csv\n",
            "Available columns: ['hours', 'attendance', 'prev_grade', 'pass']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have to define all those features and put them into arrays"
      ],
      "metadata": {
        "id": "zhzr2rb2EQ5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Features\n",
        "feature_cols = [\"hours\", \"attendance\", \"prev_grade\"]  # These are the input features\n",
        "target_col = [\"pass\"]  # This is what we want to predict (0 or 1)\n",
        "\n",
        "# Convert to NumPy arrays for training\n",
        "x = df[feature_cols].values  # feature matrix (all input data)\n",
        "y = df[target_col].values   # target vector (pass/fail outcomes)\n",
        "\n",
        "# Print shapes and sample data to verify\n",
        "print(\"Features shape:\", x.shape)\n",
        "print(\"Target shape:\", y.shape)\n",
        "print(\"\\nFirst few rows of features:\\n\", x[:5])\n",
        "print(\"\\nFirst few targets:\\n\", y[:5])"
      ],
      "metadata": {
        "id": "MWeDHTXWNdbu",
        "outputId": "281fd9ad-c242-426f-b53d-be75205042c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape: (100000, 3)\n",
            "Target shape: (100000, 1)\n",
            "\n",
            "First few rows of features:\n",
            " [[ 3.74540119 28.2587967  28.2587967 ]\n",
            " [ 9.50714306 45.86765905 45.86765905]\n",
            " [ 7.31993942  9.92154979  9.92154979]\n",
            " [ 5.98658484 44.68370253 44.68370253]\n",
            " [ 1.5601864  20.30813496 20.30813496]]\n",
            "\n",
            "First few targets:\n",
            " [[0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Go ahead and split everything into 80 train 10 valid 10 test. Also were going to need to use the mean and standard deviation in order to use everything on the same scale. after that we can covert everything into tensors"
      ],
      "metadata": {
        "id": "Q0v7LYSLEa80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split rows (80/10/10) with a shuffled index\n",
        "idx = np.arange(len(df))\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "cut_train = int(0.8 * len(df))\n",
        "cut_valid = int(0.9 * len(df))\n",
        "\n",
        "train_df = df.iloc[idx[:cut_train]].reset_index(drop=True) # Take before cut train\n",
        "valid_df = df.iloc[idx[cut_train:cut_valid]].reset_index(drop=True) #Take cut = valid train\n",
        "test_df  = df.iloc[idx[cut_valid:]].reset_index(drop=True) # Take after cut valid which is the last 10 percent\n",
        "\n",
        "# Standardize using TRAIN stats only - subtract mean and divide by std\n",
        "means = train_df[feature_cols].mean()  # Mean of training features\n",
        "stds  = train_df[feature_cols].std().replace(0, 1)  # Std dev, avoid div-by-zero\n",
        "\n",
        "Xtr = ((train_df[feature_cols] - means) / stds).values.astype(\"float32\")\n",
        "Xva = ((valid_df[feature_cols] - means) / stds).values.astype(\"float32\")\n",
        "Xte = ((test_df[feature_cols] - means) / stds).values.astype(\"float32\")\n",
        "                                                                          # Float 32 for speed and effiency\n",
        "ytr = train_df[target_col].values.astype(\"float32\").reshape(-1, 1)\n",
        "yva = valid_df[target_col].values.astype(\"float32\").reshape(-1, 1)\n",
        "yte = test_df[target_col].values.astype(\"float32\").reshape(-1, 1)\n",
        "\n",
        "# Convert to PyTorch tensors and move to GPU if available\n",
        "tXtr = torch.tensor(Xtr, device=device)\n",
        "tXva = torch.tensor(Xva, device=device)\n",
        "tXte = torch.tensor(Xte, device=device)\n",
        "tytr = torch.tensor(ytr, device=device)\n",
        "tyva = torch.tensor(yva, device=device)\n",
        "tyte = torch.tensor(yte, device=device)\n",
        "\n",
        "# Print shapes to verify\n",
        "print(\"Shapes — X:\", tXtr.shape, \"y:\", tytr.shape)"
      ],
      "metadata": {
        "id": "wKCVVvfX8mwH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6287a653-e6c4-41eb-ec41-036006add5f3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes — X: torch.Size([80000, 3]) y: torch.Size([80000, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "g6W-W1oyEsCT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up the model from scratch here using nn. Have it in a OOP structure. we have 3 layers. 1. a linear layer 2. the ReLU activation 3. another linear that outputs as a single number. We are NOT using a sigmoid here since were going to use that in the accuracy function."
      ],
      "metadata": {
        "id": "7ZfUVVvzR3GN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StudentGradePredictor(nn.Module):\n",
        "    # Define the neural network structure in a class structure - figured this is the cleanest way. Also sharpens my OOP skills\n",
        "    def __init__(self, num_inputs, hidden_size=32):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(num_inputs, hidden_size)  # First layer: inputs to hidden\n",
        "        self.relu = nn.ReLU()  # Activation function to add non-linearity\n",
        "        self.fc2 = nn.Linear(hidden_size, 1)  # Output layer: hidden to 1 output (pass/fail)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)  # Pass through first layer\n",
        "        x = self.relu(x)  # Apply activation\n",
        "        x = self.fc2(x)  # Pass through output layer (raw logits)\n",
        "        return x  # Return logits (BCEWithLogitsLoss handles sigmoid)\n",
        "\n",
        "# Get number of input features and create model\n",
        "num_inputs = tXtr.shape[1]  # Number of features (3 in this case)\n",
        "model = StudentGradePredictor(num_inputs, hidden_size=32).to(device)\n",
        "model  # Display the model structure"
      ],
      "metadata": {
        "id": "a_BECFj78z-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c87d6039-11ea-4850-9124-a628897b580d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StudentGradePredictor(\n",
              "  (fc1): Linear(in_features=3, out_features=32, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the data cleaned and the model setup we can now make the accuracy function. we turn off gradient tracking in the accuracy function as its not needed and to be more effiecient"
      ],
      "metadata": {
        "id": "_t2VTyCsSSxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()  # Disable gradient tracking to save memory\n",
        "def compute_accuracy(model, features, labels, device):\n",
        "    logits = model(features.to(device))            # Get raw model outputs\n",
        "    probabilities = torch.sigmoid(logits)          # Convert logits to probabilities\n",
        "    predictions = (probabilities >= 0.5).float()   # Convert to 0 or 1 based on threshold\n",
        "    correct = (predictions == labels.to(device)).float()  # Compare with true labels\n",
        "    accuracy = correct.mean().item()              # Average correctness\n",
        "    return accuracy\n",
        "\n",
        "    # This is just the accuracy function we will be calling it in the training loop next blocl"
      ],
      "metadata": {
        "id": "zYPLttFj-34M"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup is done! now lets train this thing.\n",
        "\n",
        "Using a Binary Cross entropy not a MSE becasue this whole project is a binary classfication. Were using the optimizer module from Pytorch to update the models parametsres after backpropagation. Then set the training loop and call in the accuracy tracker then done!"
      ],
      "metadata": {
        "id": "CF2_Fgl5Silv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.BCEWithLogitsLoss()  # Loss function for binary classification\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Optimizer with learning rate\n",
        "\n",
        "epochs = 200\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()  # Set model to training mode\n",
        "    optimizer.zero_grad()  # Clear old gradients\n",
        "\n",
        "    logits = model(tXtr)  # Get model predictions\n",
        "    loss = loss_fn(logits, tytr)  # Calculate loss\n",
        "\n",
        "    loss.backward()  # Compute gradients\n",
        "    optimizer.step()  # Update weights\n",
        "\n",
        "    if epoch == 1 or epoch % 10 == 0:\n",
        "        model.eval()  # Set model to evaluation mode\n",
        "        train_acc = compute_accuracy(model, tXtr, tytr, device)\n",
        "        valid_acc = compute_accuracy(model, tXva, tyva, device)\n",
        "        test_acc = compute_accuracy(model, tXte, tyte, device)\n",
        "        print(f\"Epoch {epoch:03d} | Loss {loss.item():.4f} | \"\n",
        "              f\"Train {train_acc:.3f} | Val {valid_acc:.3f} | Test {test_acc:.3f}\")"
      ],
      "metadata": {
        "id": "MqWhanWyLYpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e7cf2c6-e1f2-4c2a-b5b1-ba157b654719"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001 | Loss 0.6409 | Train 0.585 | Val 0.578 | Test 0.579\n",
            "Epoch 010 | Loss 0.6187 | Train 0.651 | Val 0.646 | Test 0.648\n",
            "Epoch 020 | Loss 0.5961 | Train 0.725 | Val 0.720 | Test 0.723\n",
            "Epoch 030 | Loss 0.5753 | Train 0.765 | Val 0.760 | Test 0.761\n",
            "Epoch 040 | Loss 0.5561 | Train 0.792 | Val 0.789 | Test 0.789\n",
            "Epoch 050 | Loss 0.5384 | Train 0.812 | Val 0.809 | Test 0.810\n",
            "Epoch 060 | Loss 0.5219 | Train 0.828 | Val 0.824 | Test 0.827\n",
            "Epoch 070 | Loss 0.5066 | Train 0.840 | Val 0.836 | Test 0.841\n",
            "Epoch 080 | Loss 0.4924 | Train 0.849 | Val 0.846 | Test 0.850\n",
            "Epoch 090 | Loss 0.4790 | Train 0.857 | Val 0.854 | Test 0.857\n",
            "Epoch 100 | Loss 0.4665 | Train 0.863 | Val 0.860 | Test 0.863\n",
            "Epoch 110 | Loss 0.4548 | Train 0.868 | Val 0.866 | Test 0.869\n",
            "Epoch 120 | Loss 0.4438 | Train 0.873 | Val 0.870 | Test 0.872\n",
            "Epoch 130 | Loss 0.4335 | Train 0.876 | Val 0.873 | Test 0.875\n",
            "Epoch 140 | Loss 0.4237 | Train 0.879 | Val 0.876 | Test 0.879\n",
            "Epoch 150 | Loss 0.4145 | Train 0.882 | Val 0.878 | Test 0.881\n",
            "Epoch 160 | Loss 0.4058 | Train 0.884 | Val 0.881 | Test 0.883\n",
            "Epoch 170 | Loss 0.3976 | Train 0.886 | Val 0.883 | Test 0.884\n",
            "Epoch 180 | Loss 0.3898 | Train 0.888 | Val 0.884 | Test 0.885\n",
            "Epoch 190 | Loss 0.3825 | Train 0.889 | Val 0.887 | Test 0.887\n",
            "Epoch 200 | Loss 0.3755 | Train 0.890 | Val 0.889 | Test 0.888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the model is done lets make a simple little app to use it. here were going to put the model plus scalar stats into one dictionary"
      ],
      "metadata": {
        "id": "4obgJGQriwgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Bundle model state + scaler stats into one dictonary\n",
        "checkpoint = {\n",
        "    \"model_state\": model.state_dict(),\n",
        "    \"means\": means.values.astype(\"float32\"),\n",
        "    \"stds\": stds.values.astype(\"float32\"),\n",
        "    \"feature_cols\": feature_cols\n",
        "}\n",
        "\n",
        "torch.save(checkpoint, \"student_grade_model.pkl\")\n",
        "print(\"Saved model to student_grade_model.pkl\")\n"
      ],
      "metadata": {
        "id": "kyu9me68ivqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you have the model you can know load it. This cell alows you reload the saved model"
      ],
      "metadata": {
        "id": "NA2gEMiGjOO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StudentGradePredictor(nn.Module):\n",
        "    def __init__(self, num_inputs, hidden_size=32):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(num_inputs, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, 1)\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "checkpoint = torch.load(\"student_grade_model.pkl\", map_location=\"cpu\")\n",
        "\n",
        "# Restore model\n",
        "num_inputs = len(checkpoint[\"feature_cols\"])\n",
        "model = StudentGradePredictor(num_inputs, hidden_size=32)\n",
        "model.load_state_dict(checkpoint[\"model_state\"])\n",
        "model.eval()\n",
        "\n",
        "# Restore scaler stats\n",
        "means = checkpoint[\"means\"]\n",
        "stds = checkpoint[\"stds\"]\n",
        "feature_cols = checkpoint[\"feature_cols\"]\n",
        "\n",
        "print(\"Model and scaler loaded successfully ✅\")\n"
      ],
      "metadata": {
        "id": "gN8iiONRi8y0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}